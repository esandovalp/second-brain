#ethics 
Para el final, hice una gu√≠a: [[Guia SyLE]]
# Clase 1

## Derecho

¬øQu√© es?: No solamente son las reglas escritas. Son reglas y principios flexibles (esto por los avances de la tecnolog√≠a). El derecho no es justo s√≥lo por ser derecho.

**Principio principal:** dignidad

- Imperativo categ√≥rico de Kant: el ser humano es un fin y nunca debe de ser tratado como medio

### Constituci√≥n 
- Principio de Legalidad: solamente puedes hacer lo que la ley te dice. 
- Principio de Seguridad Jur√≠dica: tener la certeza de que se va a actuar seg√∫n la ley.
	- Combate la incertidumbre del derecho.
### DDHH
- **Art√≠culo 1:** basados en la dignidad de las personas
- *def:* principios que est√°n contenidos en una constituci√≥n o en tratados internacionales dirigidos a la protecci√≥n de los seres humanos.
### Tratados Internacionales
1. Individuales 
2. Sociales
3. Ambientales
4. TICS 

Una empresa tiene: 
1. Pol√≠tica
2. Procedimientos 
3. Procesos

Un gobierno hace: 
- Pol√≠ticas P√∫blicas: acciones a largo plazo para resolver una problem√°tica, que impacta a la poblaci√≥n 

**Art√≠culo 6 de la Cons. Pol:** derecho de acceso a internet 
- ¬øA qui√©n corresponde?: al estado
- Estado: Estructura que d vida al conjunto de instituciones pol√≠ticas modernas y de las que se desprenden el sistema pol√≠tico, r√©gimen, gobierno y administraci√≥n pol√≠tica. 
- ¬øQu√© acci√≥n?: garantizar el acceso a internet a las personas.
- ¬øC√≥mo?
	1. Conseguir informaci√≥n 
	2. Hablar con el de redes 
	3. Hablar con el de obras
	4. Modems
	5. Auditorias

Divisi√≥n de poderes: 
1. Ejecutivo: hace pol√≠ticas p√∫blicas
2. Legislativo: aprueba el uso de recursos (budget)
3. Judicial: rol reactivo y de supervisi√≥n en las pol√≠ticas p√∫blicas

# Clase 2

### Organos aut√≥nomos

Con autonom√≠a presupuestal y de gesti√≥n.

**INAI**

- Transparencia
- Protecci√≥n de los datos personales
- INE
- CNDH
- Banco de M√©xico

El INAI y la CNDH van a tener que intervenir por el avance de la Inteligencia Artificial

Varios tipos de IA, el tradicional son los sistemas expertos decisionales,

Dos corrientes de la IA:

1. L√≥gica, de ah√≠ salen los sistemas expertos decisionales.
2. Biolog√≠a: redes neuronales.

1970-1990 Invierno de la IA:

- Padres del AI: Hinton.
    
- En 1996 crea las redes neuronales convolucionales, esto llev√≥ al Deep Learning, que por su parte llev√≥ a los Large Language Models
    

Debido a las redes neuronales convolucionales tenemos el Big Data, C√≥mputo en la nube, Procesadores de alta calidad.

¬øQu√© tipo de IA impacta a derechos humanos?

RE: La biol√≥gica

## **C√≥mo se forman los algoritmos**

|Sistema Experto de Decisi√≥n|Biol√≥gicos (Deep Learning) RNCP|
|---|---|
|1. Programador|1. Usuario|
|2. Experto||
|3. Usuario||

Las RNCP crean un impacto en los sectores: privados, salud, educaci√≥n, trabajadores. Es dif√≠cil decidir a quien echarle la culpa, porque es complicado regular la tecnolog√≠a.

¬øQu√© tipo de derechos tienen las m√°quinas?

Primero se debe de preguntar si toman o no decisiones que afecten al entorno.

Agencia-agente: aquel ente que tiene la capacidad de cambiar el mundo.

Responsabilidad jur√≠dica:

1. Responsabilidad subjetiva: la que directamente hace la persona a trav√©s de su voluntad que impacto de forma negativa
2. ‚Äú Objetiva: se impacta de forma negativa pero la persona no participa directamente.
    1. Ejemplo: caso Williams, padre-hijo, la responsabilidad es del padre.
    2. Ejemplo: caso Tesla, el conductor es el responsable directo.
3. ‚Äú Patrimonial del Estado: cuando un coche impacta por un bache descuidado.

Tipos de razonamiento

1. Inductivo
2. Deductive
3. Abductivo: infiere la mejor explicaci√≥n o la hip√≥tesis m√°s probable para un conjunto de observaciones o datos.
    1. Es el que hace m√°s lata en el derecho.
    2. **Toma de decisiones:**
        1. Utilitarismo: mayor beneficio para el mayor n√∫mero de personas
        2. Valores:
        3. Ley por encima de todo:

Se pueden hacer combinaciones entre los tres.

# Regulaciones que tienen que ver con CDA

1. **Uni√≥n Europea:** Actas
    1. IA: esta por aprobarse una ley
    2. Entornos digitales
    3. Comercio digital
        1. ‚Äú**Riesgos**‚Äù: hay riesgos positivos y negativos. Ejemplo de positivo, en el COVID a Zoom le fue super bien üëç
            1. **M√≠nimo**: sistema de reconocimiento, filtros de correo
            2. **Alto**: infraestructura p√∫blica, productos sanitarios, acceso a educaci√≥n, polic√≠a, migraci√≥n, justicia, democracia, biometricos, categorizaci√≥n (perfilamiento de negocio), y reconocimiento de emociones.
            3. **Inadmisible**: reconocimiento de emociones en lugar de trabajo, id biometrico remoto en lugares p√∫blicos, manipulaci√≥n de comportamiento humano, puntos de clasificaci√≥n social.
            4. **Riesgo espec√≠fico de transparencia:** claridad cuando algo ha sido creado por una IA.
        2. ¬øImpacta o no a los derechos humanos nuestro modelo de negocio?
        3. Toma decisiones
        4. Que nivel de autonom√≠a tiene ese sistema de AI
            
2. **USA:** Biden public√≥ un acuerdo para regular la IA en toda la admin p√∫blica. Tiene un sistema pol√≠tico presidencial. _Buscar orden ejecutiva de Biden sobre AI_
    1. La administraci√≥n p√∫blica son **agencias de gobierno**
    2. Regulation de la IA a trav√©s de la administraci√≥n p√∫blica
        1. Protecci√≥n de los datos de las p√∫blicas
            1. Nos llevan a los derechos humanos
3. **China:** ciberseguridad, protecci√≥n de datos, seguridad. Respeto a los valores socialistas no da√±ar el sistema, minor√≠as, informaci√≥n sexual. No discriminaci√≥n, respeto a la propiedad intelectual, I.A.G verificaci√≥n de contenido. Respeto derechos de las personas, prevenir adicciones, da√±os f√≠sicos, prohibido usar informaci√≥n privada, capacitaci√≥n del personal.
4. **Brasil:** def de un sist de AI, riesgos (toma el modelo de la UE), derecho de las personas de saber si se interactua con una AI, y de saber como es que la IA toma la decisi√≥n. Interpretabilidad, derecho a la intervenci√≥n humana. derecho a la privacidad y protecci√≥n de la data, no discriminaci√≥n, derechos de autor.
5. **Israel:** recomendaciones.
    - Adopci√≥n de una regulaci√≥n sectorial
    - Coherencia con el enfoque regulador de los principales pa√≠ses y organizaciones internacionales
    - Adopci√≥n de un enfoque basado en el riesgo
    - Utilizaci√≥n de herramientas reguladoras "blandas" que permitan un desarrollo gradual del marco regulador
    - Fomento de la cooperaci√≥n entre los sectores p√∫blico y privado.

- **Democracia:** libertad para elegir quien gobierna. La libertad es un derecho humano.

# Clase 16 02 24

*revisar apuntes para la clase de la semana pasada porque ten√≠a COVID*
## Caso 4: [[Deep fakes]] & [[Cheap-fakes]]

- El da√±o principal es la desinformaci√≥n que genera. 

## Caso 5: Literature-texts-AI

- "If you don't double check it, it becomes inmoral"
- Se debe de justificar que partes se utilizan o generan con Inteligencia Artificial 

## Caso 6: [[Cookies]] & [[FloCs]] (marketing y privacidad)

**Cookies**: informaci√≥n que usan las empresas para perfilamiento. 
- La privacidad es una restricci√≥n al uso de la informaci√≥n 
- Todos los problemas legales de la IA est√°n relacionados con la privacidad.
- **Las empresas est√°n generando su propia informaci√≥n para contraatacar la eliminaci√≥n de los cookies.** Por ejemplo, en restaurantes hacen sus cuestionarios. 

## Decisiones de las m√°quinas
### Responsabilidad jur√≠dica

- Persona y dignidad
- Libre albedr√≠o y autonom√≠a 
- Agencia -agente moral- 
- Responsabilidades y riesgos de la empresa
- Sesgos y [[auditor√≠as algor√≠tmicas]]

*tarea: buscar auditorias algoritmicas en latam*
*apuntes de esta √∫ltima clase y de la primera de  √©tica*

# Evoluci√≥n Tecnol√≥gica
*8 de marzo*
## 4ta Revoluci√≥n Tecnol√≥gica 

*Melanie Mitchell (2021) ¬øPor qu√© la IA es m√°s dif√≠cil de lo que pensamos?*

![[Pasted image 20240308103614.png]]

### Donde estamos: 

1. Alpha Go le gana a Kasparov
2. Explosi√≥n del Big Data
3. Litograf√≠a Ultravioleta
4. Geoff Hinton avance en redes neuronales profundas

**Evoluci√≥n**

1. Comunicaci√≥n 
	1. Internet, Arpanet 
	2. Open Source
2. Recabaci√≥n 
	1. Big Data
3. Almacenamiento
	1. Nube
4. Procesamiento
	1. Litograf√≠a ultravioleta extrema
5. Inversi√≥n de riesgo 
	1. Capacidad de invertir que nunca hab√≠amos tenido; inversi√≥n de riesgo. 

# Comunicaci√≥n 

## ¬øC√≥mo comunicarlo asertivamente? 

## Econom√≠a del lenguaje 

> It's all a matter of mental economy.
> 			 Daniel Kahneman

- Si bueno y breve, dos veces bueno.

## Oikos

### Administraci√≥n 

Todo comunica: 
- Voz 
- Palabras
- Ademanes
- Postura
- Gesticulaci√≥n
- Imagen

### Recursos vocales 
*agregar al FODA*

- **Volumen** (DB): intensidad  
- **Tono** (Hz): frecuencia
- **Timbre**: textura, color. Como abres y cierras la boca.  
- **Dicci√≥n** (Alta/baja definici√≥n): claridad
- **Ritmo** (Cadencia): variaci√≥n r√°pido/lento

La personalidad son todos los elementos. 

# 4ta Revoluci√≥n Industrial 

## Criterios para hablar de AGI:

1. Test de Turing 
2. Emulaci√≥n de nuestras capacidades de razonar y sentir 
3. Capacidad de m√∫ltiples funciones
4. √öltimo reto de complejidad humana autoconciencia

## Singularidad en IA

1. Desarrollo humano
2. Loop de retroalimentaci√≥n 
3. *completar*

## AGI

Para llegar a la AGI Conectando simbolismo y conectismo (*Gary Marcus*)
*Timnit Gebru*: cr√≠tica a Google, ¬øde d√≥nde sale el dinero?.
- Mucho dinero es p√∫blico, busca que la IA se use para atender problemas sociales.

# 1.2 Pensamiento ecosist√©mico 

Dos cosmovisiones
1. Mec√°nica:
	1. Se ve a la naturaleza como un mecanismo 
	2. F√≠sica newtoniana es el paradigma cient√≠fico
	3. Objeto de estudio: partes individuales y fuerzas (el todo es la suma de las partes)
	4. Causalidad: lineal 
	5. Interacci√≥n entre partes: contig√ºidad, discreci√≥n, digital
	6. Din√°mica temporal: Fijismo (la especie que ves hoy es la misma que ver√°s dentro de miles de a√±os)
	7. Orden - caos: predecible
	8. Error: anomalia corregible 
	9. Objetivo: optimizaci√≥n 
	10. Autoridad: relojero, verticalidad
	11. Antropolog√≠a: engrane - √°tomo
	12. Sociedad: f√≠sica social: agregaci√≥n de √°tomos
	13. Estado: maquinaria tecnocr√°tica
	14. Pol√≠tica (raz√≥n de estado): poder centralizado y vertical
	15. Econom√≠a (raz√≥n de mercado: acumulaci√≥n y administraci√≥n de la riqueza nacional
	16. Derecho (racionalidad penal: coercitivo: l√≥gica punitiva
Diagn√≥stico actual: 
	1. Ambiental: consumimos los recursos de 1.5 planetas tierra.
	2. Social: la desigualdad es inevitable y deseable, actualmente la desigualdad es extrema
	3. Individual: el mecanicismo ha tra√≠do mucha infelicidad 

1. Org√°nica 
*Arthur Tansley*, definici√≥n de ecosistemas
	1. Naturaleza: organismo 
	2. Paradigma cient√≠fico: Biolog√≠a 
	3. Objeto de estudio: relaciones entre partes (todo > suma)
	4. Causalidad: reticular (ecol√≥gica)
	5. Interacci√≥n entre partes: continuidad
	6. Din√°mica temporal: evoluci√≥n
	7. Orden - caos: < impredecible: azar, **emergencia**, caos
	8. Ordenador: auto-organizaci√≥n mixta: horizontal y vertical
	9. Anomal√≠a: Irregularidad: domesticable
	10. Objetivo: florecimiento  
	11. Antropolog√≠a: 
	12. Sociedad:
	13. Estado:
	14. Pol√≠tica
	15. Econom√≠a
	16. Derecho: 

# Parte de comunicaci√≥n 

**Asertividad:** es saber pedir las cosas, por ejemplo, pidiendo un aumento. 

**Logos:** Persuasi√≥n, What? -> So What? (relevancia) -> Now What? (call to action)
Tarea siguiente clase: pensar empresa social, elevator pitch 

# Clase 5 de abril 

[[Kate Crawford]] habla sobre como la IA nace en pa√≠ses de tercer mundo como Bolivia y Congo, se utiliza para lo militar, adem√°s de valorar el cr√©dito humano.

## 1.4 Ecosistema √©tico-jur√≠dico en IA

$$ \text{legalidad }+\text{etica }=\text{ justicia}$$

### 1.4.1 Agentes

- AI confiable: √©tica, legal, robusta.
- Adam Smith: ten√≠a una wide view sobre el mundo, y como se tiene que comportar en base a sus agentes. En base a esto tenemos nuestra gu√≠a (AI confiable). Sociedad civil (se desarrolla la √©tica), mercado (), legalidad ().
- El problema que existe con la tecnolog√≠a es el tiempo que se tarda en regular.
- **√âtica**: *ethos* (car√°cter) disciplina que estudia los principios y comportamientos correctos e incorrectos. O los mejores comportamientos.
	- Es el caj√≥n que contiene lo mejor a trav√©s de la historia. 
		- Hay √©pocas en las que hac√≠an cosas que actualmente son malas y viceversa.
	- Actualmente la √©tica es vista como regulador para que no te funen.
	- La √©tica se separ√≥ de la pol√≠tica:
		- *Politike*: los asuntos de la ciudad.
			- Pecado originario: "la ley mat√≥ a Socrates"
			- Aristocracia griega: mercenarios del conocimiento, sofistas.
			- Secularizaci√≥n: los gobernantes deben procurar ser temidos antes que amados. Separaci√≥n iglesia y estado.
			- Especializaci√≥n
			- Velocidad tecnol√≥gica
- Incentivos: tenemos econ√≥micos , jur√≠dico y social (no ser funado).

Territorio V.I.C.A
Volatil, Incierto, Complejo, Ambig√ºo. 
90% de decisiones y acciones lo hacemos con el sistema animal, el r√°pido.

# apuntes 12 de abril
## 1.4.2 Recursos
*Documental: True Cost*: nos dice cuanto cuesta realmente las cosas
*Libro: The Atlas of AI by Kate Crawford*

El modelo de venture capitalist se ha vuelto muy agresivo, un ejemplo de esto es Uber.
El limite del AI es:
	1. Dignidad humana
	2. Estado de derecho 
	3. Democracia?
# 26 de Abril 

1. La muestra es poco conclusiva porque es en Dinamarca
2. Hay muchas suposiciones, e.g. la gente que sale sonriendo es extrovertida
3. La clasificaci√≥n de ideolog√≠as ya es muy viejo. 

No solamente es saber de ciencia de datos, sino del negocio tambi√©n.

## Alineaci√≥n y control 

- Los algoritmos polarizan, 64% de las personas que se unen a grupos extremistas lo hacen porque el algoritmo los llevo a eso.
- El 60% de los trabajos que existen ahora, no exist√≠an en el siglo pasado.

## Desigualdad tecnol√≥gica 

- Si hay monopolios tecnol√≥gicos entonces los datos van a una sola compa√±√≠a. 
- Adem√°s tienen mucho poder de negociaci√≥n 
# **SyLE 3 de mayo 2024**

## **3. Regulaci√≥n**¬†


Hay: √âtica, mercantil y jur√≠dica¬†
### **¬øPor qu√© un Ecosistema regulatorio en IA?**¬†

- Para que cada una de las partes de la regulaci√≥n convivan.¬†


**IA confiable: √âtica, Robusta y Legal**¬†

**Alineaci√≥n:** ‚Äú¬øC√≥mo creamos un agente que se comporte de acuerdo con lo que quiere un ser humano?‚Äù¬†
Problema del genio: pides medir 6‚Äô5‚Äù y te alarga la frente.
√âtica m√°s potente: √©tica utilitarista Mill, ‚Äúmayor cantidad de felicidad para el mayor cantidad de personas‚Äù¬†
Necesitamos una √©tica que excelente: √©tica del justo medio (Arist√≥teles)
Tenemos que buscar el justo medio y darnos cuenta de cuando se vuelve excesivo de cualquier lado (agresivo por defecto o agresivo por exceso)

Principios √©ticos de la IA son 10 pero no hay que aprend√©rselos¬†

### **3 valores y 5 principios de √©tica para AI**¬†

#### **Valores:**
**Proporcionalidad**¬†
- Balance de poder: capacidades tecnol√≥gicas, vulnerabilidad de stake holders.¬†
**Dignidad Humana**¬†
**Prevenci√≥n:**
- Risk based approach (UE): quitar el ‚ÄúMove Fast and Break Things‚Äù _Buscar el de USA_¬†
#### **Principios**
- **Privacidad**
	- El pecado original de la IA es ser alimentado por datos que fueron obtenidos sin consentimiento¬†
- **Explicabilidad**
	- Tenemos que encontrar la manera de explicar como funcionan los algoritmos¬†
- **Responsabilidad**
	- Donde est√° el humano en el loop de la inteligencia artificial: ‚Äúin the loop‚Äù o ‚Äúon the loop‚Äù
- **Justicia**
	- Que no haya discriminaci√≥n, racismo, etc.¬†
- **Seguridad y Robustez**¬†
	- Protegido contra agentes mal intencionados.